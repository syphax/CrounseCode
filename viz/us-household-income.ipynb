{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental\n",
    "\n",
    "Messing around with curve fits\n",
    "\n",
    "Source data: \n",
    "\n",
    "* https://www.census.gov/data/tables/time-series/demo/income-poverty/cps-hinc/hinc-01.html\n",
    "* https://www2.census.gov/programs-surveys/cps/tables/hinc-01/2024/hinc01_1.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gamma\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import ace_tools_open as tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original data\n",
    "\n",
    "bin_descriptions = [\n",
    "    \"<5k\", \"5-10k\", \"10k-15k\", \"15k-20k\", \"20k-25k\", \"25k-30k\", \"30k-35k\", \"35k-40k\",\n",
    "    \"40k-45k\", \"45k-50k\", \"50k-55k\", \"55k-60k\", \"60k-65k\", \"65k-70k\", \"70k-75k\",\n",
    "    \"75k-80k\", \"80k-85k\", \"85k-90k\", \"90k-95k\", \"95k-100k\", \"100k-105k\", \"105k-110k\",\n",
    "    \"110k-115k\", \"115k-120k\", \"120k-125k\", \"125k-130k\", \"130k-135k\", \"135k-140k\",\n",
    "    \"140k-145k\", \"145k-150k\", \"150k-155k\", \"155k-160k\", \"160k-165k\", \"165k-170k\",\n",
    "    \"170k-175k\", \"175k-180k\", \"180k-185k\", \"185k-190k\", \"190k-195k\", \"195k-200k\"\n",
    "]\n",
    "\n",
    "midpoints = [\n",
    "    2500, 7500, 12500, 17500, 22500, 27500, 32500, 37500, 42500, 47500, 52500, 57500,\n",
    "    62500, 67500, 72500, 77500, 82500, 87500, 92500, 97500, 102500, 107500, 112500,\n",
    "    117500, 122500, 127500, 132500, 137500, 142500, 147500, 152500, 157500, 162500,\n",
    "    167500, 172500, 177500, 182500, 187500, 192500, 197500\n",
    "]\n",
    "\n",
    "\n",
    "# # Input data excluding the >200k bin\n",
    "# data = {\n",
    "#     \"Bin\": [\n",
    "#         \"<5k\", \"5-10k\", \"10k-15k\", \"15k-20k\", \"20k-25k\", \"25k-30k\", \"30k-35k\", \"35k-40k\",\n",
    "#         \"40k-45k\", \"45k-50k\", \"50k-55k\", \"55k-60k\", \"60k-65k\", \"65k-70k\", \"70k-75k\",\n",
    "#         \"75k-80k\", \"80k-85k\", \"85k-90k\", \"90k-95k\", \"95k-100k\", \"100k-105k\", \"105k-110k\",\n",
    "#         \"110k-115k\", \"115k-120k\", \"120k-125k\", \"125k-130k\", \"130k-135k\", \"135k-140k\",\n",
    "#         \"140k-145k\", \"145k-150k\", \"150k-155k\", \"155k-160k\", \"160k-165k\", \"165k-170k\",\n",
    "#         \"170k-175k\", \"175k-180k\", \"180k-185k\", \"185k-190k\", \"190k-195k\", \"195k-200k\"\n",
    "#     ],\n",
    "#     \"Pct\": [\n",
    "#         3.08, 1.35, 3.00, 3.25, 3.44, 3.48, 3.47, 3.50, 3.33, 3.42, 3.57, 3.10,\n",
    "#         3.41, 2.85, 2.76, 2.59, 2.65, 2.38, 2.47, 2.04, 2.47, 1.91, 1.91, 1.82,\n",
    "#         1.90, 1.52, 1.56, 1.36, 1.40, 1.15, 1.57, 1.06, 1.11, 0.95, 0.92, 0.82,\n",
    "#         0.98, 0.74, 0.71, 0.58\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "actual_percentages = [\n",
    "    0.0308, 0.0135, 0.0300, 0.0325, 0.0344, 0.0348, 0.0347, 0.0350, 0.0333, 0.0342,\n",
    "    0.0357, 0.0310, 0.0341, 0.0285, 0.0276, 0.0259, 0.0265, 0.0238, 0.0247, 0.0204,\n",
    "    0.0247, 0.0191, 0.0191, 0.0182, 0.0190, 0.0152, 0.0156, 0.0136, 0.0140, 0.0115,\n",
    "    0.0157, 0.0106, 0.0111, 0.0095, 0.0092, 0.0082, 0.0098, 0.0074, 0.0071, 0.0058\n",
    "]\n",
    "\n",
    "# Convert percentages to probabilities\n",
    "probabilities = actual_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand the data using midpoints and probabilities for fitting\n",
    "expanded_data = []\n",
    "for midpoint, prob in zip(midpoints, actual_percentages):\n",
    "    count = int(prob * 1000)  # Scale factor for expansion\n",
    "    expanded_data.extend([midpoint] * count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import lognorm, norm, gamma, expon, kstest\n",
    "\n",
    "# List of distributions to test\n",
    "distributions = {\n",
    "    \"Lognormal\": lognorm,\n",
    "    \"Normal\": norm,\n",
    "    \"Gamma\": gamma,\n",
    "    \"Exponential\": expon\n",
    "}\n",
    "\n",
    "# Fit each distribution and perform the Kolmogorov-Smirnov (KS) test\n",
    "fit_results = {}\n",
    "\n",
    "for dist_name, dist in distributions.items():\n",
    "    # Fit the distribution to the data\n",
    "    if dist_name in [\"Gamma\", \"Exponential\"]:  # These require a non-negative location\n",
    "        params = dist.fit(expanded_data, floc=0)\n",
    "    else:\n",
    "        params = dist.fit(expanded_data)\n",
    "    \n",
    "    # Perform KS test\n",
    "    cdf_func = lambda x: dist.cdf(x, *params)\n",
    "    ks_stat, ks_p_value = kstest(expanded_data, cdf_func)\n",
    "    \n",
    "    # Store results\n",
    "    fit_results[dist_name] = {\n",
    "        \"Parameters\": params,\n",
    "        \"KS Statistic\": ks_stat,\n",
    "        \"P-Value\": ks_p_value\n",
    "    }\n",
    "\n",
    "# Compile results into a DataFrame\n",
    "fit_comparison_df = pd.DataFrame(fit_results).T\n",
    "\n",
    "# Display the comparison of fits\n",
    "print(fit_comparison_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extend midpoints and bin descriptions to 500k\n",
    "new_bins_count = 61  # Additional bins beyond 200k\n",
    "new_midpoints = [midpoints[-1] + 5000 * i for i in range(1, new_bins_count + 1)]\n",
    "new_bin_descriptions = [\n",
    "    f\"{(200000 + 5000 * i)//1000}k-{(200000 + 5000 * (i + 1))//1000}k\" for i in range(new_bins_count - 1)\n",
    "]\n",
    "new_bin_descriptions.append(\">500k\")  # Final bin description for >500k\n",
    "\n",
    "#new_midpoints.append(500000)\n",
    "\n",
    "# Combine with original midpoints and bins\n",
    "extended_midpoints = midpoints + new_midpoints\n",
    "extended_bins = bin_descriptions + new_bin_descriptions\n",
    "\n",
    "# Extend actual percentages with NaN for bins beyond 200k\n",
    "extended_actual_percentages = actual_percentages + [None] * (len(extended_midpoints) - len(midpoints))\n",
    "\n",
    "# Assign dist parameters\n",
    "gamma_a, gamma_loc, gamma_scale = fit_comparison_df.loc[\"Gamma\", \"Parameters\"]\n",
    "lognorm_shape, lognorm_loc, lognorm_scale = fit_comparison_df.loc[\"Lognormal\", \"Parameters\"]\n",
    "\n",
    "# Calculate gamma fit percentages for the extended range\n",
    "extended_gamma_fit_percentages = []\n",
    "extended_lognorm_fit_percentages = []\n",
    "\n",
    "for i in range(len(extended_midpoints)):\n",
    "    lower_bound = extended_midpoints[i] - 2500 if i > 0 else 0  # Adjust for bin width\n",
    "    upper_bound = extended_midpoints[i] + 2500\n",
    "    \n",
    "    # Gamma fit\n",
    "    gamma_fit_percentage = gamma.cdf(upper_bound, gamma_a, loc=gamma_loc, scale=gamma_scale) - \\\n",
    "                           gamma.cdf(lower_bound, gamma_a, loc=gamma_loc, scale=gamma_scale)\n",
    "    extended_gamma_fit_percentages.append(gamma_fit_percentage)\n",
    "    \n",
    "    # Log-normal fit\n",
    "    lognorm_fit_percentage = lognorm.cdf(upper_bound, lognorm_shape, loc=lognorm_loc, scale=lognorm_scale) - \\\n",
    "                             lognorm.cdf(lower_bound, lognorm_shape, loc=lognorm_loc, scale=lognorm_scale)\n",
    "    extended_lognorm_fit_percentages.append(lognorm_fit_percentage)\n",
    "\n",
    "# Create the extended DataFrame\n",
    "extended_comparison_df = pd.DataFrame({\n",
    "    \"Original Bin\": extended_bins,\n",
    "    \"Bin Midpoints\": extended_midpoints,\n",
    "    \"Actual Percentages\": extended_actual_percentages,\n",
    "    \"Gamma Fit Percentages\": extended_gamma_fit_percentages,\n",
    "    \"Log-Normal Fit Percentages\": extended_lognorm_fit_percentages\n",
    "})\n",
    "\n",
    "# Display the results\n",
    "print(extended_comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract data for plotting\n",
    "midpoints = extended_comparison_df[\"Bin Midpoints\"]\n",
    "actual_percentages = extended_comparison_df[\"Actual Percentages\"]\n",
    "gamma_fit_percentages = extended_comparison_df[\"Gamma Fit Percentages\"]\n",
    "lognorm_fit_percentages = extended_comparison_df[\"Log-Normal Fit Percentages\"]\n",
    "\n",
    "# Plot actual percentages as bars\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.bar(midpoints, actual_percentages, width=4000, alpha=0.6, label=\"Actual Percentages\", color=\"skyblue\")\n",
    "\n",
    "# Plot gamma fit percentages as a line\n",
    "plt.plot(midpoints, gamma_fit_percentages, label=\"Gamma Fit Percentages\", color=\"orange\", linewidth=2)\n",
    "\n",
    "# Plot log-normal fit percentages as a line\n",
    "plt.plot(midpoints, lognorm_fit_percentages, label=\"Log-Normal Fit Percentages\", color=\"green\", linewidth=2)\n",
    "\n",
    "# Formatting the plot\n",
    "plt.title(\"Comparison of Actual vs Gamma and Log-Normal Fit Percentages\", fontsize=16)\n",
    "plt.xlabel(\"Income Bin Midpoints ($)\", fontsize=14)\n",
    "plt.ylabel(\"Percentage of Households\", fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.xticks(ticks=midpoints[::5], labels=[f\"{int(m/1000)}k\" for m in midpoints[::5]], rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geometric?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Define geometric decay model\n",
    "def geometric_decay(x, y0, r):\n",
    "    return y0 * r**x\n",
    "\n",
    "# Extract data starting from around 50,000\n",
    "start_index = np.where(filtered_midpoints >= 50000)[0][0]\n",
    "geom_midpoints = filtered_midpoints[start_index:]\n",
    "geom_probabilities = filtered_probabilities[start_index:]\n",
    "\n",
    "# Convert midpoints to indices for the decay model\n",
    "indices = np.arange(len(geom_midpoints))\n",
    "\n",
    "# Fit the geometric decay model\n",
    "popt, _ = curve_fit(geometric_decay, indices, geom_probabilities, p0=[geom_probabilities[0], 0.9])\n",
    "\n",
    "# Generate the fitted curve\n",
    "fitted_geom_curve = geometric_decay(indices, *popt)\n",
    "\n",
    "# Extend indices to project the geometric curve to $500,000\n",
    "extended_indices = np.arange(len(geom_midpoints) + 100)\n",
    "extended_geom_curve = geometric_decay(extended_indices, *popt)\n",
    "extended_midpoints = np.concatenate([geom_midpoints, \n",
    "                                      geom_midpoints[-1] + np.arange(1, len(extended_indices) - len(geom_midpoints) + 1) * 5000])\n",
    "\n",
    "# Plot the full dataset and extended geometric decay curve\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(filtered_midpoints, filtered_probabilities, width=3000, alpha=0.6, label=\"Original Data\")\n",
    "plt.plot(extended_midpoints, extended_geom_curve, label=\"Geometric Decay Fit (Extended)\", linestyle=\"--\", linewidth=2)\n",
    "plt.title(\"Full Dataset with Extended Geometric Decay Curve\")\n",
    "plt.xlabel(\"Income ($)\")\n",
    "plt.ylabel(\"Probability\")\n",
    "#plt.axvline(x=500000, color=\"red\", linestyle=\":\", label=\"Projection to $500,000\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_geom_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align the length of extended_geom_curve to match extended_midpoints\n",
    "geom_fit_full_padded = np.concatenate([[None] * start_index, extended_geom_curve])\n",
    "\n",
    "# Adjust all columns to the same length\n",
    "actual_data_padded = np.concatenate([filtered_probabilities, [None] * (len(extended_midpoints) - len(filtered_probabilities))])\n",
    "geom_fit_full_padded = geom_fit_full_padded[:len(extended_midpoints)]\n",
    "\n",
    "# Create the updated DataFrame\n",
    "results_df_updated = pd.DataFrame({\n",
    "    \"Midpoints\": extended_midpoints,\n",
    "    \"Actual Data (Probabilities)\": actual_data_padded,\n",
    "    \"Geometric Curve Fit (>50k)\": geom_fit_full_padded\n",
    "})\n",
    "\n",
    "#results_df_updated['cum_geo'] = results_df_updated['Geometric Curve Fit (>50k)'].cumsum()\n",
    "\n",
    "tools.display_dataframe_to_user(name=\"Updated Geometric Decay Fit Results\", dataframe=results_df_updated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_updated.loc[results_df_updated['Midpoints'] > 500000, 'Geometric Curve Fit (>50k)'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
